{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUlhNVAObqE5"
   },
   "source": [
    "# Implementação do algoritimo completo, sem compromisso com  perfomance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import operator\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import multiprocessing as mp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lXxVfg2r6YrR"
   },
   "source": [
    "# Função match\n",
    "\n",
    "![Match function](./img/match_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kG6AUH5q6lAv"
   },
   "outputs": [],
   "source": [
    "def cluster_matching_function(weight_matrix,\n",
    "                              cluster_number,\n",
    "                              element,\n",
    "                              prototypes,\n",
    "                              dissimilarity_matrices):\n",
    "    \"\"\"\n",
    "        :params: weight_matrix: numpy array-like \n",
    "                    matriz K x P de pesos das matrizes de dissimilaridades por cluster\n",
    "                cluster_number: int\n",
    "                    Número do cluster em questão\n",
    "                element: int\n",
    "                    Índice do elemento (entre 0 e N-1)\n",
    "                prototypes: list like\n",
    "                    Lista de tamanho K dos protótipos de cada cluster\n",
    "                dissimilarity_matrices: lista de numpy array\n",
    "                    Lista de matrizes de dissimilaridade\n",
    "\n",
    "        :return: float\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Criando aliases compatíveis com as variáveis da fórmula\n",
    "    k = cluster_number\n",
    "    D = dissimilarity_matrices\n",
    "    p = len(D)\n",
    "    Gk = prototypes[k]\n",
    "    l = weight_matrix\n",
    "\n",
    "    dissimilarities_sum = np.array([dj[element, Gk].sum() for dj in D])\n",
    "\n",
    "    return np.dot(l[k], dissimilarities_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EdvnqRHK8wBq"
   },
   "source": [
    "# Função objetivo\n",
    "\n",
    "![Objetive function](./img/objective_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CUfSEUkfcAnN"
   },
   "outputs": [],
   "source": [
    "def objective_function(clusters_qtd,\n",
    "                       elements_qtd,\n",
    "                       adequacy_criterion,\n",
    "                       m,\n",
    "                       weight_matrix,\n",
    "                       prototypes,\n",
    "                       dissimilarity_matrices):\n",
    "    \"\"\"\n",
    "        :params: clusters_qtd: int\n",
    "                    Quantidade total de clusters\n",
    "                elements_qtd: int\n",
    "                    Quantidade de elementos da base de dados\n",
    "                adequacy_criterion: numpy array-like\n",
    "                    Matriz u de tamanho N x K contendo a índice de adequação \n",
    "                    de cada elemente a cada cluster\n",
    "                m: int\n",
    "                    Fator de ponderação do índice de adequação\n",
    "                weight_matrix:\n",
    "                     matriz K x P de pesos das matrizes de dissimilaridades por cluster\n",
    "                prototypes: list like\n",
    "                    Lista de tamanho K dos protótipos de cada cluster\n",
    "                dissimilarity_matrices: lista de numpy array\n",
    "                    Lista de matrizes de dissimilaridade\n",
    "\n",
    "        :return: float\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    u = np.power(adequacy_criterion, m) # Resolvendo a exponeciação de u de uma vez só\n",
    "    l = weight_matrix\n",
    "    D = dissimilarity_matrices\n",
    "    K = clusters_qtd\n",
    "    G = prototypes\n",
    "    N = elements_qtd\n",
    "    match = cluster_matching_function # Criando um alias para reduzir o nome da função de matching\n",
    "  \n",
    "    J = np.array([np.array([u[i, k] * match(l, k, i, G, D) for i in range(N)]).sum() \n",
    "          for k in range(K)])\n",
    "\n",
    "\n",
    "    return J.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MzyvZQxb9Iiy"
   },
   "source": [
    "# Protótipos\n",
    "\n",
    "![Prototype function](./img/prototype_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40yFT3299PVp"
   },
   "outputs": [],
   "source": [
    "def get_prototypes(elements_qtd,\n",
    "                   q,\n",
    "                   m,\n",
    "                   s,\n",
    "                   cluster_number,\n",
    "                   adequacy_criterion,\n",
    "                   dissimilarity_matrices,\n",
    "                   weight_matrix):\n",
    "    \"\"\"\n",
    "        :params:\n",
    "                elements_qtd: int \n",
    "                    Quantidade de elementos da base de dados\n",
    "                q: int\n",
    "                    Quantidade de elementos protótipos\n",
    "                m: int\n",
    "                    Fator de ponderação do índice de adequação\n",
    "                s: int\n",
    "                    Fator de ponderação dos pesos das matrizes\n",
    "                cluster_number: int\n",
    "                    Quantidade total de clusters\n",
    "                adequacy_criterion: numpy array-like\n",
    "                    Matriz u de tamanho N x K contendo a índice de adequação \n",
    "                    de cada elemente a cada cluster\n",
    "                dissimilarity_matrices: lista de numpy array\n",
    "                    Lista de matrizes de dissimilaridade\n",
    "                weight_matrix: \n",
    "                     matriz K x P de pesos das matrizes de dissimilaridades por cluster\n",
    "\n",
    "        :return: list\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    G = []\n",
    "    k = cluster_number\n",
    "    D = dissimilarity_matrices\n",
    "    u = np.power(adequacy_criterion, m)\n",
    "    l = np.power(weight_matrix, s)\n",
    "    N = elements_qtd\n",
    "    p = len(D)\n",
    "    \n",
    "    p_sums = np.empty((p, N))\n",
    "    \n",
    "    for j in range(p):\n",
    "        p_sums[j, :] = (D[j] * l[k,j]).sum(axis=1) \n",
    "    \n",
    "    p_sums = p_sums.sum(axis=0)\n",
    "  \n",
    "    p_sums_rotten = u[:, k].flatten() * p_sums\n",
    "    return p_sums_rotten.argsort()[-q:][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MzyvZQxb9Iiy"
   },
   "source": [
    "# Protótipos Dummy\n",
    "\n",
    "![Prototype function](./img/prototype_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0] [1, 2]\n"
     ]
    }
   ],
   "source": [
    "def get_prototypes_dummy2(elements_qtd,\n",
    "                       q,\n",
    "                       m,\n",
    "                       s,\n",
    "                       cluster_number,\n",
    "                       adequacy_criterion,\n",
    "                       dissimilarity_matrices,\n",
    "                       weight_matrix):\n",
    "    G = []\n",
    "    k = cluster_number\n",
    "    D = dissimilarity_matrices\n",
    "    u = np.power(adequacy_criterion, m)\n",
    "    l = np.power(weight_matrix, s)\n",
    "    N = elements_qtd\n",
    "    P = len(D)\n",
    "    \n",
    "    while (len(G) != q):\n",
    "        menor_soma = 999999\n",
    "        menor_indice = None\n",
    "        \n",
    "        for h in range(N): \n",
    "            if h in G:\n",
    "                continue\n",
    "            \n",
    "            dists_p = np.array([D[j][:, h] * l[k,j] for j in range(P)]) #shape: NxP\n",
    "            sums_p = dists_p.sum(axis=0)\n",
    "            soma = np.dot(u[:, k], sums_p)\n",
    "            \n",
    "            if soma < menor_soma:\n",
    "                menor_soma = soma\n",
    "                menor_indice = h\n",
    "                 \n",
    "        G.append(menor_indice)\n",
    "        \n",
    "    return G\n",
    "            \n",
    "\n",
    "a = get_prototypes(elements_qtd = 3,\n",
    "                   q=2,\n",
    "                   m=1.6,\n",
    "                   s=1,\n",
    "                   cluster_number=0,\n",
    "                   adequacy_criterion = np.array([[1,2,3],[3,2,1],[0,1,3]]),\n",
    "                   dissimilarity_matrices= [np.array([[0, .5, .1],[.3, 0, .1], [1, .2, 0]])],\n",
    "                   weight_matrix=np.array([[0.8],[0.5]]))\n",
    "\n",
    "b = get_prototypes_dummy2(elements_qtd = 3,\n",
    "                   q=2,\n",
    "                   m=1.6,\n",
    "                   s=1,\n",
    "                   cluster_number=0,\n",
    "                   adequacy_criterion = np.array([[1,2,3],[3,2,1],[0,1,3]]),\n",
    "                   dissimilarity_matrices= [np.array([[0, .5, .1],[.3, 0, .1], [1, .2, 0]])],\n",
    "                   weight_matrix=np.array([[0.8],[0.5]]))\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmu24Eka9wdS"
   },
   "source": [
    "# Matriz de relevâcia\n",
    "\n",
    "![Funções de peso](./img/vector_weights_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02tqmGYnBImF"
   },
   "outputs": [],
   "source": [
    "def compute_relevance_weights(clusters_qtd,\n",
    "                              dissimilarity_matrices,\n",
    "                              prototypes,\n",
    "                              elements_qtd,\n",
    "                              adequacy_criterion,\n",
    "                              m):\n",
    "    \"\"\"\n",
    "        :params:\n",
    "                clusters_qtd: int\n",
    "                    Quantidade total de clusters\n",
    "                dissimilarity_matrices: lista de numpy array\n",
    "                    Lista de matrizes de dissimilaridade\n",
    "                prototypes: list like\n",
    "                    Lista de tamanho K dos protótipos de cada cluster\n",
    "                elements_qtd: int\n",
    "                    Quantidade de elementos da base de dados\n",
    "                adequacy_criterion: numpy array-like\n",
    "                    Matriz u de tamanho N x K contendo a índice de adequação \n",
    "                    de cada elemente a cada cluster\n",
    "                m: int\n",
    "                    Fator de ponderação do índice de adequação\n",
    "\n",
    "        :return: numpy array of shape K x P\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    D = dissimilarity_matrices\n",
    "    P = len(D)\n",
    "    Gk = prototypes\n",
    "    K = clusters_qtd\n",
    "    N = elements_qtd\n",
    "    u = np.power(adequacy_criterion, m)\n",
    "    l = np.zeros((K, P))\n",
    "\n",
    "    def match(element, Dh, G):\n",
    "        \"\"\"\n",
    "            Função auxiliar para cálculo de match entre um elemento \n",
    "            qualquer, os protótipos G de um cluster específico e uma matriz \n",
    "            de similaridade específica Dh.\n",
    "        \"\"\"\n",
    "\n",
    "        return Dh[element, G].sum()\n",
    "\n",
    "    for k in range(K):\n",
    "        # Calculado o somatório do numerador da equação à esquerda da igualdade\n",
    "        weight_diss_sum1 = np.array([np.array([u[i, k] * match(i, D[h], Gk[k]) for i in range(N)]).sum()\n",
    "                            for h in range(P)])\n",
    "        for j in range(P):\n",
    "     \n",
    "            # Calculado o somatório do denominador da equação à esquerda da igualdade\n",
    "            weight_diss_sum2 = np.array([u[i, k] * match(i, D[j], Gk[k])\n",
    "                                    for i in range(N)]).sum()\n",
    "            \n",
    "#             weight_diss_sum2 = weight_diss_sum1[j]\n",
    "\n",
    "            # Executando a divisão da fração à esquerda da equação\n",
    "            l[k, j] = math.pow(weight_diss_sum1.prod(), 1/P) / weight_diss_sum2\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grau de pertinência\n",
    "\n",
    "![Fórmula grau de pertinência](./img/membership_degree.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_membership_degree(weight_matrix,\n",
    "                              prototypes,\n",
    "                              clusters_qtd,\n",
    "                              dissimilarity_matrices,\n",
    "                              elements_qtd,\n",
    "                              m):\n",
    "    \"\"\"\n",
    "        :params: weight_matrix: numpy array-like \n",
    "                    matriz K x P de pesos das matrizes de dissimilaridades por cluster\n",
    "                prototypes: list like\n",
    "                    Lista de tamanho K dos protótipos de cada cluster\n",
    "                clusters_qtd: int\n",
    "                    Quantidade total de clusters\n",
    "                dissimilarity_matrices: lista de numpy array\n",
    "                    Lista de matrizes de dissimilaridade\n",
    "                elements_qtd: int\n",
    "                    Quantidade de elementos da base de dados\n",
    "                m: int\n",
    "                    Fator de ponderação do índice de adequação\n",
    "\n",
    "        :return: numpy array NxK\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "\n",
    "    K = clusters_qtd\n",
    "    G = prototypes\n",
    "    D = dissimilarity_matrices\n",
    "    l = weight_matrix\n",
    "    P = len(D)\n",
    "    N = elements_qtd\n",
    "    u = np.zeros((N, K))\n",
    "    \n",
    "    match = cluster_matching_function # Criando um alias para reduzir o nome da função de matching\n",
    "\n",
    "    def ratio(element, k, h):\n",
    "        r = match(l, k, element, G, D) / match(l, h, element, G, D)\n",
    "        return math.pow(r, 1/(m-1))\n",
    "\n",
    "    for i in range(N):\n",
    "        for k in range(K):\n",
    "            outter_sum = np.array([ratio(i, k, h) for h in range(K)]).sum()\n",
    "            u[i, k] = 1/outter_sum\n",
    "\n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SS-G2leHdobn"
   },
   "source": [
    "# Carregando Matrizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2gEvW3EdWJT"
   },
   "outputs": [],
   "source": [
    "def carregar_matrizes(data_path = None):\n",
    "    data_path = data_path or \"./data\"\n",
    "    data_path = os.path.abspath(data_path)\n",
    "    \n",
    "    FAC_FILE = os.path.join(data_path, \"mfeat-fac-dissimilarity.npy\")\n",
    "    FOU_FILE = os.path.join(data_path, \"mfeat-fou-dissimilarity.npy\")\n",
    "    KAR_FILE = os.path.join(data_path, \"mfeat-kar-dissimilarity.npy\")\n",
    "\n",
    "    fac_dis = np.load(FAC_FILE)\n",
    "    fou_dis = np.load(FOU_FILE)\n",
    "    kar_dis = np.load(KAR_FILE)\n",
    "    \n",
    "    return fac_dis, fou_dis, kar_dis\n",
    "\n",
    "data_path = sys.argv[1] if len(sys.argv) == 2 else None\n",
    "fac_dis, fou_dis, kar_dis = carregar_matrizes(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo completo\n",
    "> Partitioning fuzzy K-medoids clustering algorithms with relevance weight for each dissimilarity matrix estimated locally\n",
    "\n",
    "* Parametros: $K = 10; m = 1.6; T = 150; \\epsilon = 10^{−10};$\n",
    "* Devemos considerar a iniciarlizar do vetor de pesos como sendo 1, já que usamos a equação 9 (MFCMdd-RWL-P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_prototypes(K, N, q, seed):\n",
    "    elements = set(range(N))\n",
    "    protos = []\n",
    "    random.seed(seed)\n",
    "    \n",
    "    for k in range(K):\n",
    "        protos.append(random.sample(elements, q))\n",
    "        elements -= set(protos[-1])\n",
    "\n",
    "    return protos\n",
    "\n",
    "def assert_relevance_weights_prod_one(l):\n",
    "    # l.shape == (K,P)\n",
    "    prods_p = l.prod(axis=1)\n",
    "    assert round(prods_p.sum()) == l.shape[0], f\"O produto dos pesos de relevância não é igual a 1 ({prods_p.sum()})\"\n",
    "\n",
    "def assert_membership_degree_sum_one(u):\n",
    "     # u.shape == (N,K)\n",
    "    sums_k = u.sum(axis=1)\n",
    "    assert round(sums_k.sum()) == u.shape[0], f\"A soma dos pesos de relevância não é igual a 1 ({sums_k.sum()})\"\n",
    "\n",
    "def executar_treinamento(dissimilarity_matrices,\n",
    "                       elements_qtd,\n",
    "                       K=10,\n",
    "                       m=1.6,\n",
    "                       T=150,\n",
    "                       epsilon=10e-10,\n",
    "                       q=2, \n",
    "                       seed=13082020,\n",
    "                       prototipos = None):\n",
    "\n",
    "    D = dissimilarity_matrices\n",
    "    N = elements_qtd\n",
    "    P = len(D)\n",
    "\n",
    "    last_lambda = np.ones((K, P))\n",
    "    last_prototypes = prototipos or random_prototypes(K, N, q, seed)\n",
    "    last_membership_degree = None\n",
    "    last_cost = None\n",
    "    \n",
    "    assert_relevance_weights_prod_one(last_lambda)\n",
    "\n",
    "#     print(\"Passo 0\")\n",
    "#     print(\"Calculando matriz de adequação inicial (u0)\")\n",
    "    u0 = compute_membership_degree(weight_matrix=last_lambda,\n",
    "                                   prototypes=last_prototypes,\n",
    "                                   clusters_qtd=K,\n",
    "                                   dissimilarity_matrices=dissimilarity_matrices,\n",
    "                                   elements_qtd=N,\n",
    "                                   m=m)\n",
    "    \n",
    "#     assert_membership_degree_sum_one(u0)\n",
    "\n",
    "#     print(\"Calculando função de custo inicial (J0)\")\n",
    "    J0 = objective_function(clusters_qtd=K,\n",
    "                            elements_qtd=N,\n",
    "                            adequacy_criterion=u0,\n",
    "                            m=m,\n",
    "                            weight_matrix=last_lambda,\n",
    "                            prototypes=last_prototypes,\n",
    "                            dissimilarity_matrices=dissimilarity_matrices)\n",
    "    \n",
    "    last_membership_degree = u0\n",
    "    last_cost = J0\n",
    "    \n",
    "    for t in range(1, T):\n",
    "#         print(f\"Passo {t}/{T}\")\n",
    "        \n",
    "#         print(\">> Calculando protótipos\")\n",
    "        new_prototypes = [get_prototypes_dummy2(elements_qtd=N,\n",
    "                                         q=q,\n",
    "                                         m=m,\n",
    "                                         s=1,\n",
    "                                         cluster_number=k,\n",
    "                                         adequacy_criterion=last_membership_degree,\n",
    "                                         dissimilarity_matrices=D,\n",
    "                                         weight_matrix=last_lambda) for k in range(K)]\n",
    "        \n",
    "        #print(\"new_prototypes.shape\", new_prototypes)\n",
    "        \n",
    "#         print(\">> Calculando matriz de relevâncias\")\n",
    "        new_lambda = compute_relevance_weights(clusters_qtd=K,\n",
    "                                               dissimilarity_matrices=D,\n",
    "                                               prototypes=new_prototypes,\n",
    "                                               elements_qtd=N,\n",
    "                                               adequacy_criterion=last_membership_degree,\n",
    "                                               m=m)\n",
    "        \n",
    "#         assert_relevance_weights_prod_one(new_lambda)\n",
    "    \n",
    "#         print(\">> Calculando grau de pertinência\")\n",
    "        new_degree = compute_membership_degree(weight_matrix=new_lambda,\n",
    "                                               prototypes=new_prototypes,\n",
    "                                               clusters_qtd=K,\n",
    "                                               dissimilarity_matrices=dissimilarity_matrices,\n",
    "                                               elements_qtd=N,\n",
    "                                               m=m)\n",
    "    \n",
    "        \n",
    "#         assert_membership_degree_sum_one(new_degree)\n",
    "\n",
    "#         print(\">> Calculando função objetivo\")\n",
    "        new_cost = objective_function(clusters_qtd=K,\n",
    "                                      elements_qtd=N,\n",
    "                                      adequacy_criterion=new_degree,\n",
    "                                      m=m,\n",
    "                                      weight_matrix=new_lambda,\n",
    "                                      prototypes=new_prototypes,\n",
    "                                      dissimilarity_matrices=dissimilarity_matrices)\n",
    "\n",
    "        last_prototypes = new_prototypes\n",
    "        last_lambda = new_lambda\n",
    "        last_membership_degree = new_degree\n",
    "#         print(\">> Cost: \", new_cost)\n",
    "        \n",
    "        if abs(last_cost - new_cost) <= epsilon:\n",
    "            last_cost = new_cost\n",
    "            break\n",
    "    \n",
    "        last_cost = new_cost\n",
    "        \n",
    "    data = {\n",
    "        \"cost\":last_cost,\n",
    "        \"membership_degree\":last_membership_degree,\n",
    "        \"prototypes\":last_prototypes,\n",
    "        \"weight_matrix\":last_lambda,\n",
    "        \"times\": t,\n",
    "        \"q\": q,\n",
    "        \"K\":K,\n",
    "        \"m\":m,\n",
    "        \"seed\": seed,\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de exportação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    " \n",
    "def export_best_result(data, file_name):\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def export_fuzzy_partitions_to_csv(data, file_name):\n",
    "    df = pd.DataFrame(data[\"membership_degree\"])\n",
    "    df.to_csv(file_name, index=False, decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executando 100x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_algoritmo(dissimilarity_matrices, N, times=100, **kwargs):\n",
    "\n",
    "    best = None\n",
    "    \n",
    "    seeds = [18082020 + i for i in range(times)]\n",
    "    with mp.Pool() as p:\n",
    "        results = []\n",
    "        for seed in seeds:\n",
    "            kwargs[\"seed\"] = seed\n",
    "            r = p.apply_async(executar_treinamento, (dissimilarity_matrices, N), kwargs)\n",
    "            results.append(r)\n",
    "            \n",
    "        for i, r in enumerate(results):\n",
    "            data = r.get()\n",
    "            print(f\"Execução {i+1}/{times}\")\n",
    "            print(\">> Cost: \", data[\"cost\"] )\n",
    "            if (not best) or data[\"cost\"] < best[\"cost\"]:\n",
    "                best = data \n",
    "        \n",
    "            \n",
    "    return best\n",
    "\n",
    "TIMES = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execução 1/1\n",
      ">> Cost:  6665.410166578429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6665.410166578429"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gk = [[1403,1372],[213,1170],[465,1442],[1380,182],[1793,218],[1212,143],[215,995],[1875,416],[840,693],[1643,1811]]\n",
    "\n",
    "melhor_resultado_todas = executar_algoritmo([fac_dis, fou_dis, kar_dis], \n",
    "                                            2000, \n",
    "                                            times=1, \n",
    "                                            prototipos=Gk)\n",
    "\n",
    "export_best_result(melhor_resultado_todas, \"data/melhor_resultado_todas.pickle\")\n",
    "export_fuzzy_partitions_to_csv(melhor_resultado_todas, \"data/fuzzy_partitions_todas.csv\")\n",
    "\n",
    "melhor_resultado_todas[\"cost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melhor_resultado_fac = executar_algoritmo([fac_dis], 2000, times=TIMES)\n",
    "export_best_result(melhor_resultado_fac, \"data/melhor_resultado_fac.pickle\")\n",
    "export_fuzzy_partitions_to_csv(melhor_resultado_fac, \"data/fuzzy_partitions_fac.csv\")\n",
    "\n",
    "melhor_resultado_fac[\"cost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melhor_resultado_fou = executar_algoritmo([fou_dis], 2000, times=TIMES)\n",
    "export_best_result(melhor_resultado_fou, \"data/melhor_resultado_fou.pickle\")\n",
    "export_fuzzy_partitions_to_csv(melhor_resultado_fou, \"data/fuzzy_partitions_fou.csv\")\n",
    "\n",
    "melhor_resultado_fou[\"cost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melhor_resultado_kar = executar_algoritmo([kar_dis], 2000, times=TIMES)\n",
    "export_best_result(melhor_resultado_kar, \"data/melhor_resultado_kar.pickle\")\n",
    "export_fuzzy_partitions_to_csv(melhor_resultado_kar, \"data/fuzzy_partitions_kar.csv\")\n",
    "\n",
    "melhor_resultado_kar[\"cost\"]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02_clusterizar_lazy_version.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
