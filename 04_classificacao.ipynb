{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i) Regra da soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_PATH = \"./data\"\n",
    "\n",
    "FAC_FILE = os.path.join(DATA_BASE_PATH, \"mfeat-fac\")\n",
    "FOU_FILE = os.path.join(DATA_BASE_PATH, \"mfeat-fou\")\n",
    "KAR_FILE = os.path.join(DATA_BASE_PATH, \"mfeat-kar\")\n",
    "\n",
    "fac = np.loadtxt(FAC_FILE, dtype=int)\n",
    "fou = np.loadtxt(FOU_FILE, dtype=float)\n",
    "kar = np.loadtxt(KAR_FILE, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando melhor resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = clustering.import_best_result(\"data/melhor_resultado_todas.pickle\")\n",
    "partition, y_true = clustering.get_hard_patitions(best_result[\"membership_degree\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidade à priori das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1175, 0.116 , 0.1355, 0.1465, 0.0405, 0.01  , 0.1305, 0.151 ,\n",
       "       0.0815, 0.071 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pw = np.array([len(c)/2000 for c in partition])\n",
    "Pw"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i, idxs in enumerate(partition):\n",
    "    pd.DataFrame(fac[idxs]).to_csv(f\"data/fac{i}.csv\",decimal=\",\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.DataFrame(partition).to_csv(f\"data/partition.csv\",decimal=\",\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de densidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_gaussian_density_prob(xk, d, means, var, cov_matrix):\n",
    "#     coef = np.power(2*np.pi, -d/2) \n",
    "#     inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "#     (sign, logdet) = np.linalg.slogdet(inv_cov_matrix)\n",
    "#     sqrt_det_inv_cov = np.sqrt(sign*np.exp(logdet))\n",
    "#     diff = xk - means\n",
    "#     exp_exp = np.dot((-1/2)*np.dot(diff.T, inv_cov_matrix), diff)\n",
    "#     exp_func = np.exp(exp_exp)\n",
    "    \n",
    "#     return coef * sqrt_det_inv_cov * exp_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def calc_gaussian_bayesian_data(x, partition):\n",
    "#     n,d = x.shape\n",
    "#     qtd_w = len(partition)\n",
    "#     means = np.array([x[idxs].mean(axis=0) for idxs in partition])\n",
    "#     var = np.array([((x[idxs]-means[i])**2).mean(axis=0) for i, idxs in enumerate(partition)])\n",
    "#     cov_matrix = [np.zeros((d,d)) for _ in range(qtd_w)]\n",
    "\n",
    "#     for i in range(qtd_w):\n",
    "#         np.fill_diagonal(cov_matrix[i], var[i])\n",
    "                \n",
    "#     p_x_w = np.empty((n, qtd_w))\n",
    "    \n",
    "#     for k in range(n):\n",
    "#         for i in range(qtd_w):\n",
    "#             p_x_w[k, i] = calc_gaussian_density_prob(x[k], d, means[i], var[i], cov_matrix[i])   \n",
    "    \n",
    "#     return p_x_w\n",
    "\n",
    "def calc_prob_posteriori(p_x_w, Pw):\n",
    "    qtd_x, qtd_w = p_x_w.shape \n",
    "    p_w_x = np.empty((qtd_x, qtd_w))\n",
    "    \n",
    "    for k in range(qtd_x):\n",
    "        for i in range(qtd_w):\n",
    "            sum_all = np.dot(p_x_w[k], Pw)\n",
    "            p_w_x[k,i] = (p_x_w[k,i] * Pw[i])/sum_all\n",
    "       \n",
    "    return p_w_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Densidades por dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fac_byn_density_probs = calc_gaussian_bayesian_data(fac, partition)\n",
    "# fou_byn_density_probs = calc_gaussian_bayesian_data(fou, partition)\n",
    "# kar_byn_density_probs = calc_gaussian_bayesian_data(kar, partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fac_byn_density_probs[0,0], fou_byn_density_probs[0,0], kar_byn_density_probs[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob. à posteriori por view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fac_byn_posteriori_probs = calc_prob_posteriori(fac_byn_density_probs, Pw)\n",
    "# fou_byn_posteriori_probs = calc_prob_posteriori(fou_byn_density_probs, Pw)\n",
    "# kar_byn_posteriori_probs = calc_prob_posteriori(kar_byn_density_probs, Pw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regra da soma\n",
    "\n",
    "Precisei tirar o fac porque seus valores são nulos. TENTAR CORRIGIR ISSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regra_soma_padrao(views, Pw):\n",
    "    qtd_x = views[0].shape[0]\n",
    "    qtd_w = len(Pw)\n",
    "    x_sum_w = np.empty((qtd_x, qtd_w))\n",
    "\n",
    "    for i in range(qtd_x):\n",
    "        for k in range(qtd_w):\n",
    "            views_sum = sum([v[i,k] for v in views])\n",
    "            x_sum_w[i,k] = (1-len(views))*Pw[k] + views_sum\n",
    "                    \n",
    "    y_pred = x_sum_w.argmax(axis = 1) \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimador do scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "class ClassificaforBayesiano(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, partition, Pw):\n",
    "        self.partition = partition\n",
    "        self.Pw = Pw\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "         \n",
    "        self.classes_ = unique_labels(y)\n",
    "        self._fit_gaussian_bayesian_data(X)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        return self\n",
    "    \n",
    "    def _fit_gaussian_bayesian_data(self, X):\n",
    "        n, d = X.shape\n",
    "        qtd_w = len(self.partition)\n",
    "        self.means = np.array([X[idxs].mean(axis=0) for idxs in self.partition])\n",
    "        self.var = np.array([((X[idxs]-self.means[i])**2).mean(axis=0) for i, idxs in enumerate(self.partition)])\n",
    "        self.cov_matrix = [np.zeros((d,d)) for _ in range(qtd_w)]\n",
    "\n",
    "        for i in range(qtd_w):\n",
    "            np.fill_diagonal(self.cov_matrix[i], self.var[i])\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _calc_gaussian_density_prob(self, xk, cls):\n",
    "        d = xk.shape[0]\n",
    "        coef = np.power(2*np.pi, -d/2)\n",
    "        inv_cov_matrix = np.linalg.inv(self.cov_matrix[cls])\n",
    "        (sign, logdet) = np.linalg.slogdet(inv_cov_matrix)\n",
    "        sqrt_det_inv_cov = np.sqrt(sign*np.exp(logdet))\n",
    "        diff = xk - self.means[cls]\n",
    "        exp_exp = np.dot((-1/2)*np.dot(diff.T, inv_cov_matrix), diff)\n",
    "        exp_func = np.exp(exp_exp)\n",
    "\n",
    "        return coef * sqrt_det_inv_cov * exp_func\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        \n",
    "        desity_probs = np.empty((X.shape[0], len(self.classes_)))\n",
    "        for k in range(desity_probs.shape[0]):\n",
    "            for j in range(len(self.classes_)):\n",
    "                desity_probs[k,j] = self._calc_gaussian_density_prob(X[k], j)\n",
    "        \n",
    "        post_probs = calc_prob_posteriori(desity_probs, self.Pw)\n",
    "        \n",
    "        return post_probs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegraSomaClasificadorBayesiano(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, partition, Pw):\n",
    "#         self.views = views\n",
    "        self.partition = partition\n",
    "        self.Pw = Pw\n",
    "        self.clfs = []        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "#         X, y = check_X_y(X, y)\n",
    "         \n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        for x in X:\n",
    "            clf = ClassificaforBayesiano(self.partition, Pw)\n",
    "            clf.fit(x,y)\n",
    "            self.clfs.append(clf)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        assert len(X) == len(self.clfs)\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "#         X = check_array(X)\n",
    "        \n",
    "        post_probs = [clf.predict_proba(x) for clf, x in zip(self.clfs, X)]\n",
    "        \n",
    "        return self.regra_soma(post_probs, Pw=self.Pw)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"Pw\": self.Pw, \"partition\": self.partition}\n",
    "    \n",
    "    def regra_soma(self, matrizes, Pw):\n",
    "        qtd_x = matrizes[0].shape[0]\n",
    "        qtd_w = len(Pw)\n",
    "        x_sum_w = np.empty((qtd_x, qtd_w))\n",
    "        \n",
    "        for i in range(qtd_x):\n",
    "            for k in range(qtd_w):\n",
    "                views_sum = sum([v[i,k] for v in matrizes])\n",
    "                # views_sum =  fac_p_w_x[i,k] fou_p_w_x[i,k] + kar_p_w_x[i,k]\n",
    "                x_sum_w[i,k] = (1-len(matrizes))*Pw[k] + views_sum\n",
    "                \n",
    "        y_pred = x_sum_w.argmax(axis = 1) \n",
    "        return y_pred\n",
    "\n",
    "# def regra_soma_padrao(fac_p_w_x, fou_p_w_x, kar_p_w_x, Pw):\n",
    "# x_sum_w = np.empty((10, 2000))\n",
    "\n",
    "# for i in range(10):\n",
    "#     for k in range(2000):\n",
    "#         views_sum =  fou_p_w_x[i,k] + kar_p_w_x[i,k]\n",
    "#         # views_sum =  fac_p_w_x[i,k] fou_p_w_x[i,k] + kar_p_w_x[i,k]\n",
    "#         x_sum_w[i,k] = (1-2)*Pw[i] + views_sum\n",
    "\n",
    "# y_pred = x_sum_w.argmax(axis = 0) \n",
    "# return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação cruzada\n",
    "\n",
    "- **Observação**: No modelo gaussiano,  as desidades de probabilidades da VIEW1 (mfeat-fac) são todas zeradas, o que causa uma baixa na performance geral do modelo da regra da soma. Por esta razão, apenas neste modelo, ela foi desconsiderada. Portanto, no modelo gaussiano apresentamos os resultados os dados considerando somente VIEW2 e VIEW3.\n",
    "\n",
    "- As médias das métricas para cada split da validação estão no arquivo **data/gaussian_training_data.csv**. Nota-se que muitos resultados aprensetam valores altos ou representações do infinito (\"inf\"). Isso se deu por conta de problemas de overflow na multiplicação usando valores muito pequenos fato que, aparentemente, foi causado pela quantidade de splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass n_splits=10, n_repeats=30, random_state=42 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/300 2/300 3/300 4/300 5/300 6/300 7/300 8/300 9/300 10/300 11/300 12/300 13/300 14/300 15/300 16/300 17/300 18/300 19/300 20/300 21/300 22/300 23/300 24/300 25/300 26/300 27/300 28/300 29/300 30/300 31/300 32/300 33/300 34/300 35/300 36/300 37/300 38/300 39/300 "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "FOLDS = 10\n",
    "REPEATS = 30\n",
    "REAPEATS_GAUSSIAN = 10\n",
    "\n",
    "def get_splited_partition(idxs, y_true):\n",
    "    partition = [[] for i in range(10)]\n",
    "    \n",
    "    for i,indice in enumerate(idxs):\n",
    "        partition[y_true[indice]].append(i)\n",
    "        \n",
    "    return partition\n",
    "    \n",
    "cv = RepeatedStratifiedKFold(FOLDS, REPEATS, RANDOM_SEED)\n",
    "\n",
    "train_precision_scores = np.empty((cv.get_n_splits(),))\n",
    "train_recall_scores = np.empty((cv.get_n_splits(),))\n",
    "train_f1_scores = np.empty((cv.get_n_splits(),))\n",
    "train_acc_scores = np.empty((cv.get_n_splits(),))\n",
    "\n",
    "test_precision_scores = np.empty((cv.get_n_splits(),))\n",
    "test_recall_scores = np.empty((cv.get_n_splits(),))\n",
    "test_f1_scores = np.empty((cv.get_n_splits(),))\n",
    "test_acc_scores = np.empty((cv.get_n_splits(),))\n",
    "\n",
    "#views = [fac, fou, kar]\n",
    "views = [fou, kar]\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(cv.split(fac, y_true)):\n",
    "    print(f\"{i+1}/{cv.get_n_splits()}\", end=\" \")\n",
    "    \n",
    "    test_views = [v[test_index] for v in views]\n",
    "    train_views = [v[train_index] for v in views]\n",
    "    \n",
    "    local_partition = get_splited_partition(train_index, y_true)\n",
    "    clf = RegraSomaClasificadorBayesiano(local_partition, Pw)\n",
    "    \n",
    "    clf.fit(train_views, y_true[train_index])\n",
    "    \n",
    "    y_pred_train = clf.predict(train_views)\n",
    "    y_pred_test = clf.predict(test_views)\n",
    "    \n",
    "    scores_train = precision_recall_fscore_support(y_true[train_index], \n",
    "                                                       y_pred_train, \n",
    "                                                       average=\"macro\")\n",
    "\n",
    "    train_precision_scores[i] = scores_train[0]\n",
    "    train_recall_scores[i] = scores_train[1]\n",
    "    train_f1_scores[i] = scores_train[2]\n",
    "    train_acc_scores[i] = accuracy_score(y_true[train_index], y_pred_train)\n",
    "\n",
    "    scores_test = precision_recall_fscore_support(y_true[test_index], \n",
    "                                                   y_pred_test, \n",
    "                                                   average=\"macro\")\n",
    "\n",
    "    test_precision_scores[i] = scores_test[0]\n",
    "    test_recall_scores[i] = scores_test[1]\n",
    "    test_f1_scores[i] = scores_test[2]\n",
    "    test_acc_scores[i] = accuracy_score(y_true[test_index], y_pred_test)\n",
    "\n",
    "    report = dict(\n",
    "        runs = cv.get_n_splits(),\n",
    "        split=i+1,\n",
    "        train_accuracy = train_acc_scores[i],\n",
    "        train_precision = train_precision_scores[i],\n",
    "        train_recall = train_recall_scores[i],\n",
    "        train_fscore = train_f1_scores.mean(),\n",
    "        test_accuracy = test_acc_scores.mean(),\n",
    "        test_precision = test_precision_scores[i],\n",
    "        test_recall = test_recall_scores[i],\n",
    "        test_fscore = test_f1_scores[i],\n",
    "\n",
    "    )\n",
    "\n",
    "    if os.path.exists(\"data/gaussian_300_splits.csv\"):\n",
    "        pd.DataFrame([report]).to_csv(\"data/gaussian_300_splits.csv\", mode=\"a\", header=False, decimal=\",\", index=False)\n",
    "    else:\n",
    "        pd.DataFrame([report]).to_csv(\"data/gaussian_300_splits.csv\", mode=\"a\", header=True, decimal=\",\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento com base completa\n",
    "\n",
    "- O objetivo aqui é determinar o desempenho do classificador por classe, tendo em vista diversas métricas de classificação. Observar os resultados no arquivo **data/gaussian_classification_report.txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#views = [fac, fou, kar]\n",
    "views = [fou, kar]\n",
    "\n",
    "clf = RegraSomaClasificadorBayesiano(partition, Pw)\n",
    "\n",
    "clf.fit(views, y_true)\n",
    "\n",
    "y_pred = clf.predict(views)\n",
    "\n",
    "report = classification_report(y_true, y_pred, output_dict=False, digits=4)\n",
    "\n",
    "acc_score_gaussian = accuracy_score(y_true, y_pred)\n",
    "\n",
    "with open(\"data/gaussian_classification_report.txt\", \"w\") as report_file:\n",
    "    report_file.write(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimativa pontual e intervalo de confiança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = acc_score_gaussian\n",
    "z_padrao = 1.96 # Confiança de 95%\n",
    "\n",
    "def calc_intervalo_confiança(p, z=z_padrao, n=2000):\n",
    "    diff = z*np.sqrt(p*(1-p)/n)\n",
    "    return (round(p - diff, 4), round(p+diff, 4))\n",
    "\n",
    "print(\"Estimativa pontual: \", p)\n",
    "print(\"Intervalo de confiança: \", calc_intervalo_confiança(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii) K-Vizinhos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "fac_norm = minmax_scale(fac)\n",
    "fou_norm = minmax_scale(fou)\n",
    "kar_norm = minmax_scale(kar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distâncias entre os elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "fac_dist = euclidean_distances(fac_norm, fac_norm)\n",
    "fou_dist = euclidean_distances(fou_norm, fou_norm)\n",
    "kar_dist = euclidean_distances(kar_norm, kar_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de densidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_knn_density_prob(view_dists, k, Pw, y_true):\n",
    "    qtd_x = view_dists.shape[0]\n",
    "    qtd_w = len(Pw)\n",
    "    \n",
    "    p_x_w = np.empty((qtd_x, qtd_w))\n",
    "    k_vizinhos = view_dists.argsort(axis=1)[:,:k+1]\n",
    "    \n",
    "    for j in range(qtd_x):\n",
    "        w_vizinhos = y_true[k_vizinhos[j, 1:]]\n",
    "        for i in range(qtd_w):\n",
    "            p_x_w[j,i] = (w_vizinhos == i).sum()/k\n",
    "                    \n",
    "    return p_x_w\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desidades por dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fac_knn_density_probs = calc_knn_density_prob(fac_dist, 5, Pw, y_true)\n",
    "# fou_knn_density_probs = calc_knn_density_prob(fou_dist, 5, Pw, y_true)\n",
    "# kar_knn_density_probs = calc_knn_density_prob(kar_dist, 5, Pw, y_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob. à posteriori por view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fac_knn_posteriori_probs = calc_prob_posteriori(fac_knn_density_probs, Pw)\n",
    "# fou_knn_posteriori_probs = calc_prob_posteriori(fou_knn_density_probs, Pw)\n",
    "# kar_knn_posteriori_probs = calc_prob_posteriori(kar_knn_density_probs, Pw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regra da soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_knn_all = regra_soma_padrao([fac_knn_posteriori_probs, \n",
    "#                                    fou_knn_posteriori_probs, \n",
    "#                                    kar_knn_posteriori_probs], Pw)\n",
    "\n",
    "# print(\"Acurácia: \", accuracy_score(y_true, y_pred_knn_all))\n",
    "# print(\"Medida-F: \", f1_score(y_true, y_pred_knn_all, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "cv = RepeatedStratifiedKFold(FOLDS, REPEATS, RANDOM_SEED)\n",
    "\n",
    "\n",
    "k_range = range(3,4)\n",
    "views = [fac, fou, kar]\n",
    "\n",
    "for k in k_range:\n",
    "    \n",
    "    train_precision_scores = np.empty((cv.get_n_splits(),))\n",
    "    train_recall_scores = np.empty((cv.get_n_splits(),))\n",
    "    train_f1_scores = np.empty((cv.get_n_splits(),))\n",
    "\n",
    "    test_precision_scores = np.empty((cv.get_n_splits(),))\n",
    "    test_recall_scores = np.empty((cv.get_n_splits(),))\n",
    "    test_f1_scores = np.empty((cv.get_n_splits(),))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(cv.split(fac, y_true)):\n",
    "        print(f\"[k={k}] {i+1}/{cv.get_n_splits()}\", end=\" \")\n",
    "\n",
    "        train_views = [minmax_scale(v[train_index]) for v in views]\n",
    "        test_views = [minmax_scale(v[test_index]) for v in views]\n",
    "\n",
    "        train_views_dists = [euclidean_distances(v,v) for v in train_views]\n",
    "        test_views_dists = [euclidean_distances(v,v) for v in test_views]\n",
    "\n",
    "    #     y_true_split = get_splited_partition(train_index, y_true)\n",
    "\n",
    "        train_views_density_probs = [calc_knn_density_prob(v, k, Pw, y_true[train_index]) \n",
    "                                     for v in train_views_dists]\n",
    "\n",
    "        train_views_post_probs = [calc_prob_posteriori(v, Pw) \n",
    "                                  for v in train_views_density_probs]\n",
    "\n",
    "        y_pred_train = regra_soma_padrao(train_views_post_probs, Pw)\n",
    "\n",
    "\n",
    "        test_views_density_probs = [calc_knn_density_prob(v, k, Pw, y_true[test_index]) \n",
    "                                     for v in test_views_dists]\n",
    "\n",
    "        test_views_post_probs = [calc_prob_posteriori(v, Pw) \n",
    "                                  for v in test_views_density_probs]\n",
    "\n",
    "        y_pred_test = regra_soma_padrao(test_views_post_probs, Pw)\n",
    "        \n",
    "        scores_train = precision_recall_fscore_support(y_true[train_index], \n",
    "                                                       y_pred_train, \n",
    "                                                       average=\"macro\")\n",
    "        \n",
    "#         train_precision_scores[i] = scores_train[0]\n",
    "#         train_recall_scores[i] = scores_train[1]\n",
    "#         train_f1_scores[i] = scores_train[2]\n",
    "\n",
    "#         scores_test = precision_recall_fscore_support(y_true[test_index], \n",
    "#                                                        y_pred_test, \n",
    "#                                                        average=\"macro\")\n",
    "        \n",
    "#         test_precision_scores[i] = scores_test[0]\n",
    "#         test_recall_scores[i] = scores_test[1]\n",
    "#         test_f1_scores[i] = scores_test[2]\n",
    "        \n",
    "        \n",
    "        train_precision_scores[i] = scores_train[0]\n",
    "        train_recall_scores[i] = scores_train[1]\n",
    "        train_f1_scores[i] = scores_train[2]\n",
    "        train_acc_scores[i] = accuracy_score(y_true[train_index], y_pred_train)\n",
    "\n",
    "        scores_test = precision_recall_fscore_support(y_true[test_index], \n",
    "                                                       y_pred_test, \n",
    "                                                       average=\"macro\")\n",
    "\n",
    "        test_precision_scores[i] = scores_test[0]\n",
    "        test_recall_scores[i] = scores_test[1]\n",
    "        test_f1_scores[i] = scores_test[2]\n",
    "        test_acc_scores[i] = accuracy_score(y_true[test_index], y_pred_test)\n",
    "        \n",
    "        report = dict(\n",
    "            runs = cv.get_n_splits(),\n",
    "            split=i+1,\n",
    "            train_accuracy = train_acc_scores[i],\n",
    "            train_precision = train_precision_scores[i],\n",
    "            train_recall = train_recall_scores[i],\n",
    "            train_fscore = train_f1_scores[i],\n",
    "            test_accuracy = test_acc_scores[i],\n",
    "            test_precision = test_precision_scores[i],\n",
    "            test_recall = test_recall_scores[i],\n",
    "            test_fscore = test_f1_scores[i],\n",
    "        )\n",
    "\n",
    "        if os.path.exists(\"data/knn_300_splits.csv\"):\n",
    "            pd.DataFrame([report]).to_csv(\"data/knn_300_splits.csv\", mode=\"a\", header=False, decimal=\",\", index=False)\n",
    "        else:\n",
    "            pd.DataFrame([report]).to_csv(\"data/knn_300_splits.csv\", mode=\"a\", header=True, decimal=\",\", index=False)\n",
    "        \n",
    "#     report = dict(\n",
    "#         k = k,\n",
    "#         runs = cv.get_n_splits(),\n",
    "#         train_precision = train_precision_scores.mean(),\n",
    "#         train_precision_std = train_precision_scores.std(),\n",
    "#         train_recall = train_recall_scores.mean(),\n",
    "#         train_recall_std = train_recall_scores.std(),\n",
    "#         train_fscore = train_f1_scores.mean(),\n",
    "#         train_fscore_std = train_f1_scores.std(),\n",
    "#         test_precision = test_precision_scores.mean(),\n",
    "#         test_precision_std = test_precision_scores.std(),\n",
    "#         test_recall = test_recall_scores.mean(),\n",
    "#         test_recall_std = test_recall_scores.std(),\n",
    "#         test_fscore = test_f1_scores.mean(),\n",
    "#         test_fscore_std = test_f1_scores.std(),\n",
    "        \n",
    "#     )\n",
    "    \n",
    "#     if os.path.exists(\"data/knn_300_splits.csv\"):\n",
    "#         pd.DataFrame([report]).to_csv(\"data/knn_300_splits.csv\", mode=\"a\", header=False, decimal=\",\", index=False)\n",
    "#     else:\n",
    "#         pd.DataFrame([report]).to_csv(\"data/knn_300_splits.csv\", mode=\"a\", header=True, decimal=\",\", index=False)\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "#         if test_f1_scores[:i+1].mean() > best_data[\"f1_scores\"].mean():\n",
    "#             best_data[\"f1_scores\"] = test_f1_scores[:i+1]\n",
    "#             best_data[\"k\"] = k\n",
    "            \n",
    "#             print(f\"\\nMelhor k: {k}\")\n",
    "#             print(f\"Acurácia de treino parcial: {train_acc_scores[:i+1].mean():4} +/- ({train_acc_scores[:i+1].std():4})\")\n",
    "#             print(f\"Medida-F de treino parcial: {train_f1_scores[:i+1].mean():4} +/- ({train_f1_scores[:i+1].std():4})\\n\")\n",
    "\n",
    "#             print(f\"Acurácia de test parcial: {test_acc_scores[:i+1].mean():4} +/- ({test_acc_scores[:i+1].std():4})\")\n",
    "#             print(f\"Medida-F de test parcial: {test_f1_scores[:i+1].mean():4} +/- ({test_f1_scores[:i+1].std():4})\\n\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento com melhor valor de K\n",
    "\n",
    "- O objetivo aqui é determinar o desempenho do classificador o valor de K com o qual ovtivemos a melhor medida-f média através validação cruzada. Observar os resultados no arquivo **data/knn_classification_report.txt**\n",
    "- O melhor valor de K pode ser observado no arquivo **data/knn_best_k.csv**, gerado no experimento anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "BEST_K = 3\n",
    "#views = [fac, fou, kar]\n",
    "views = [fac, fou, kar]\n",
    "\n",
    "train_views = [minmax_scale(v) for v in views]\n",
    "\n",
    "train_views_dists = [euclidean_distances(v,v) for v in train_views]\n",
    "\n",
    "train_views_density_probs = [calc_knn_density_prob(v, BEST_K, Pw, y_true) \n",
    "                             for v in train_views_dists]\n",
    "\n",
    "train_views_post_probs = [calc_prob_posteriori(v, Pw) \n",
    "                          for v in train_views_density_probs]\n",
    "\n",
    "y_pred = regra_soma_padrao(train_views_post_probs, Pw)\n",
    "      \n",
    "acc_score_knn = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "report = classification_report(y_true, y_pred, output_dict=False, digits=4)\n",
    "\n",
    "with open(\"data/knn_classification_report.txt\", \"w\") as report_file:\n",
    "    report_file.write(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimativa pontual e intervalo de confiança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = acc_score_knn\n",
    "z_padrao = 1.96 # Confiança de 95%\n",
    "\n",
    "print(\"Estimativa pontual: \", p)\n",
    "print(\"Intervalo de confiança: \", calc_intervalo_confiança(p, z_padrao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iii) Janela de Parzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de densidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parzen_density_function(view, h, partition):\n",
    "    qtd_x = view.shape[0]\n",
    "    qtd_w = len(partition)\n",
    "    \n",
    "    p_x_w = np.empty((qtd_x, qtd_w))\n",
    "    dims = view.shape[1]\n",
    "    \n",
    "    for i in range(qtd_w):\n",
    "        n = len(partition[i])\n",
    "        x_view = view[partition[i],:]\n",
    "        for k in range(qtd_x):\n",
    "            diff = (view[k] - x_view)/h\n",
    "            gaussian_kernel = np.exp(-(diff**2)/2)/np.sqrt(2*np.pi)\n",
    "            prod_dims = gaussian_kernel.prod(axis=1)\n",
    "            p_x_w[k,i] = prod_dims.sum()/(n*h**dims)\n",
    "            \n",
    "    return p_x_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fac_parzen_density_probs = parzen_density_function(fac, 2, partition)\n",
    "# fou_parzen_density_probs = parzen_density_function(fou, 2, partition)\n",
    "# kar_parzen_density_probs = parzen_density_function(kar, 2, partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob. à posteriori por view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fac_prazen_posteriori_probs = calc_prob_posteriori(fac_parzen_density_probs, Pw)\n",
    "# fou_prazen_posteriori_probs = calc_prob_posteriori(fou_parzen_density_probs, Pw)\n",
    "# kar_prazen_posteriori_probs = calc_prob_posteriori(kar_parzen_density_probs, Pw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regra da soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for h in range(2, 21, 1):\n",
    "#     fac_parzen_density_probs = parzen_density_function(fac, h, partition)\n",
    "#     fou_parzen_density_probs = parzen_density_function(fou, h, partition)\n",
    "#     kar_parzen_density_probs = parzen_density_function(kar, h, partition)\n",
    "\n",
    "#     fac_prazen_posteriori_probs = calc_prob_posteriori(fac_parzen_density_probs, Pw)\n",
    "#     fou_prazen_posteriori_probs = calc_prob_posteriori(fou_parzen_density_probs, Pw)\n",
    "#     kar_prazen_posteriori_probs = calc_prob_posteriori(kar_parzen_density_probs, Pw)\n",
    "\n",
    "#     y_pred_prazen_all = regra_soma_padrao([fac_prazen_posteriori_probs, \n",
    "#                                        fou_prazen_posteriori_probs, \n",
    "#                                        kar_prazen_posteriori_probs], Pw)\n",
    "\n",
    "#     print(f\"h: {h}\")\n",
    "#     print(\"Acurácia: \", accuracy_score(y_true, y_pred_prazen_all))\n",
    "#     print(\"Medida-F: \", f1_score(y_true, y_pred_prazen_all, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação cruzada\n",
    "\n",
    "- Variamos h de 2 a 12 para fins de comparação. Não foi possíve, na validação cruzada, avaliar valores de janela maiores por limitação de tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(FOLDS, REPEATS, RANDOM_SEED)\n",
    "train_acc_scores = np.empty((cv.get_n_splits(),))\n",
    "train_f1_scores = np.empty((cv.get_n_splits(),))\n",
    "\n",
    "test_acc_scores = np.empty((cv.get_n_splits(),))\n",
    "test_f1_scores = np.empty((cv.get_n_splits(),))\n",
    "\n",
    "\n",
    "h_range = range(2,3)\n",
    "best_data = {\"f1_scores\": np.zeros((1,)), \n",
    "             \"h\":None}\n",
    "\n",
    "views = [fac, fou, kar]\n",
    "\n",
    "y_true = y_true.astype(int)\n",
    "for h in h_range:\n",
    "    train_precision_scores = np.empty((cv.get_n_splits(),))\n",
    "    train_recall_scores = np.empty((cv.get_n_splits(),))\n",
    "    train_f1_scores = np.empty((cv.get_n_splits(),))\n",
    "    train_acc_scores = np.empty((cv.get_n_splits(),))\n",
    "\n",
    "    test_precision_scores = np.empty((cv.get_n_splits(),))\n",
    "    test_recall_scores = np.empty((cv.get_n_splits(),))\n",
    "    test_f1_scores = np.empty((cv.get_n_splits(),))\n",
    "    test_acc_scores = np.empty((cv.get_n_splits(),))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(cv.split(fac, y_true)):\n",
    "        print(f\"[h={h}] {i+1}/{cv.get_n_splits()}\", end=\" \")\n",
    "\n",
    "        train_views = [v[train_index] for v in views]\n",
    "        test_views = [v[test_index] for v in views]\n",
    "\n",
    "        \n",
    "        y_true_split = get_splited_partition(train_index, y_true)\n",
    "        \n",
    "\n",
    "        train_views_density_probs = [parzen_density_function(v, h, y_true_split) \n",
    "                                     for v in train_views]\n",
    "\n",
    "        train_views_post_probs = [calc_prob_posteriori(v, Pw) \n",
    "                                  for v in train_views_density_probs]\n",
    "\n",
    "        y_pred_train = regra_soma_padrao(train_views_post_probs, Pw)\n",
    "\n",
    "\n",
    "        y_true_split = get_splited_partition(test_index, y_true)\n",
    "        \n",
    "        test_views_density_probs = [parzen_density_function(v, h, y_true_split) \n",
    "                                     for v in test_views]\n",
    "\n",
    "        test_views_post_probs = [calc_prob_posteriori(v, Pw) \n",
    "                                  for v in test_views_density_probs]\n",
    "\n",
    "        y_pred_test = regra_soma_padrao(test_views_post_probs, Pw)\n",
    "\n",
    "        scores_train = precision_recall_fscore_support(y_true[train_index], \n",
    "                                                       y_pred_train, \n",
    "                                                       average=\"macro\")\n",
    "\n",
    "        train_precision_scores[i] = scores_train[0]\n",
    "        train_recall_scores[i] = scores_train[1]\n",
    "        train_f1_scores[i] = scores_train[2]\n",
    "        train_acc_scores[i] = accuracy_score(y_true[train_index], y_pred_train)\n",
    "\n",
    "        scores_test = precision_recall_fscore_support(y_true[test_index], \n",
    "                                                       y_pred_test, \n",
    "                                                       average=\"macro\")\n",
    "\n",
    "        test_precision_scores[i] = scores_test[0]\n",
    "        test_recall_scores[i] = scores_test[1]\n",
    "        test_f1_scores[i] = scores_test[2]\n",
    "        test_acc_scores[i] = accuracy_score(y_true[test_index], y_pred_test)\n",
    "        \n",
    "        report = dict(\n",
    "            runs = cv.get_n_splits(),\n",
    "            split=i+1,\n",
    "            train_accuracy = train_acc_scores[i],\n",
    "            train_precision = train_precision_scores[i],\n",
    "            train_recall = train_recall_scores[i],\n",
    "            train_fscore = train_f1_scores[i],\n",
    "            test_accuracy = test_acc_scores[i],\n",
    "            test_precision = test_precision_scores[i],\n",
    "            test_recall = test_recall_scores[i],\n",
    "            test_fscore = test_f1_scores[i],\n",
    "        )\n",
    "\n",
    "        if os.path.exists(\"data/parzen_300_splits.csv\"):\n",
    "            pd.DataFrame([report]).to_csv(\"data/parzen_300_splits.csv\", mode=\"a\", header=False, decimal=\",\", index=False)\n",
    "        else:\n",
    "            pd.DataFrame([report]).to_csv(\"data/parzen_300_splits.csv\", mode=\"a\", header=True, decimal=\",\", index=False)\n",
    "\n",
    "        \n",
    "#         report = dict(\n",
    "#             h = h,\n",
    "#             runs = cv.get_n_splits(),\n",
    "#             train_precision = train_precision_scores.mean(),\n",
    "#             train_precision_std = train_precision_scores.std(),\n",
    "#             train_recall = train_recall_scores.mean(),\n",
    "#             train_recall_std = train_recall_scores.std(),\n",
    "#             train_fscore = train_f1_scores.mean(),\n",
    "#             train_fscore_std = train_f1_scores.std(),\n",
    "#             test_precision = test_precision_scores.mean(),\n",
    "#             test_precision_std = test_precision_scores.std(),\n",
    "#             test_recall = test_recall_scores.mean(),\n",
    "#             test_recall_std = test_recall_scores.std(),\n",
    "#             test_fscore = test_f1_scores.mean(),\n",
    "#             test_fscore_std = test_f1_scores.std(),\n",
    "#         )\n",
    "\n",
    "#     if os.path.exists(\"data/parzen_300_splits.csv\"):\n",
    "#         pd.DataFrame([report]).to_csv(\"data/parzen_300_splits.csv\", mode=\"a\", header=False, decimal=\",\", index=False)\n",
    "#     else:\n",
    "#         pd.DataFrame([report]).to_csv(\"data/parzen_300_splits.csv\", mode=\"a\", header=True, decimal=\",\", index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento com melhor valor de h\n",
    "\n",
    "- O objetivo aqui é determinar o desempenho do classificador o valor de h com o qual ovtivemos a melhor medida-f média através validação cruzada. Observar os resultados no arquivo **data/parzen_classification_report_h2.txt**\n",
    "- Contudo, assim como com a validação cruzada, o modelo obteve 100% em todas as medidas, para todos os valores de h e em ambas as bases de treinamento e validação.\n",
    "\n",
    "- Valores de h a partir de 30 causaram underflow no trenamento graças à poderação exponecial feita no cálculo da função de densidade do modelo e portanto não puderam ser computadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "BEST_H = 2\n",
    "#views = [fac, fou, kar]\n",
    "views = [fac, fou, kar]\n",
    "\n",
    "train_views_density_probs = [parzen_density_function(v, BEST_H, partition) \n",
    "                             for v in views]\n",
    "\n",
    "train_views_post_probs = [calc_prob_posteriori(v, Pw) \n",
    "                          for v in train_views_density_probs]\n",
    "\n",
    "y_pred = regra_soma_padrao(train_views_post_probs, Pw)\n",
    "\n",
    "report = classification_report(y_true, y_pred, output_dict=False, digits=4)\n",
    "\n",
    "acc_score_parzen = accuracy_score(y_true, y_pred)\n",
    "\n",
    "with open(f\"data/parzen_classification_report_h{BEST_H}.txt\", \"w\") as report_file:\n",
    "    report_file.write(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimativa pontual e intervalo de confiança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = acc_score_parzen\n",
    "z_padrao = 1.96 # Confiança de 95%\n",
    "\n",
    "print(\"Estimativa pontual: \", p)\n",
    "print(\"Intervalo de confiança: \", calc_intervalo_confiança(p, z_padrao))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "262px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
