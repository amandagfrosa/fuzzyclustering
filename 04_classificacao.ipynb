{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i) Regra da soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_PATH = \"./data\"\n",
    "\n",
    "FAC_FILE = os.path.join(DATA_BASE_PATH, \"mfeat-fac\")\n",
    "FOU_FILE = os.path.join(DATA_BASE_PATH, \"mfeat-fou\")\n",
    "KAR_FILE = os.path.join(DATA_BASE_PATH, \"mfeat-kar\")\n",
    "\n",
    "fac = np.loadtxt(FAC_FILE, dtype=int)\n",
    "fou = np.loadtxt(FOU_FILE, dtype=float)\n",
    "kar = np.loadtxt(KAR_FILE, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando melhor resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = clustering.import_best_result(\"data/melhor_resultado_todas.pickle\")\n",
    "partition, y_true = clustering.get_hard_patitions(best_result[\"membership_degree\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidade à priori das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1175, 0.116 , 0.1355, 0.1465, 0.0405, 0.01  , 0.1305, 0.151 ,\n",
       "       0.0815, 0.071 ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pw = np.array([len(c)/2000 for c in partition])\n",
    "Pw"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i, idxs in enumerate(partition):\n",
    "    pd.DataFrame(fac[idxs]).to_csv(f\"data/fac{i}.csv\",decimal=\",\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.DataFrame(partition).to_csv(f\"data/partition.csv\",decimal=\",\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de densidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gaussian_density_prob(xk, d, means, var, cov_matrix):\n",
    "    coef = np.power(2*np.pi, -d/2) \n",
    "    inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "    (sign, logdet) = np.linalg.slogdet(inv_cov_matrix)\n",
    "    sqrt_det_inv_cov = np.sqrt(sign*np.exp(logdet))\n",
    "    diff = xk - means\n",
    "    exp_exp = np.dot((-1/2)*np.dot(diff.T, inv_cov_matrix), diff)\n",
    "    exp_func = np.exp(exp_exp)\n",
    "    \n",
    "    return coef * sqrt_det_inv_cov * exp_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_gaussian_bayesian_data(x, partition):\n",
    "    n,d = x.shape\n",
    "    qtd_w = len(partition)\n",
    "    means = np.array([x[idxs].mean(axis=0) for idxs in partition])\n",
    "    var = np.array([((x[idxs]-means[i])**2).mean(axis=0) for i, idxs in enumerate(partition)])\n",
    "    cov_matrix = [np.zeros((d,d)) for _ in range(qtd_w)]\n",
    "\n",
    "    for i in range(qtd_w):\n",
    "        np.fill_diagonal(cov_matrix[i], var[i])\n",
    "                \n",
    "    p_x_w = np.empty((n, qtd_w))\n",
    "    \n",
    "    for k in range(n):\n",
    "        for i in range(qtd_w):\n",
    "            p_x_w[k, i] = calc_gaussian_density_prob(x[k], d, means[i], var[i], cov_matrix[i])   \n",
    "    \n",
    "    return p_x_w\n",
    "\n",
    "def calc_prob_posteriori(p_x_w, Pw):\n",
    "    qtd_x, qtd_w = p_x_w.shape \n",
    "    p_w_x = np.empty((qtd_x, qtd_w))\n",
    "    \n",
    "    for k in range(qtd_x):\n",
    "        for i in range(qtd_w):\n",
    "            sum_all = np.dot(p_x_w[k], Pw)\n",
    "            p_w_x[k,i] = (p_x_w[k,i] * Pw[i])/sum_all\n",
    "       \n",
    "    return p_w_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Densidades por dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac_byn_density_probs = calc_gaussian_bayesian_data(fac, partition)\n",
    "fou_byn_density_probs = calc_gaussian_bayesian_data(fou, partition)\n",
    "kar_byn_density_probs = calc_gaussian_bayesian_data(kar, partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 3.243154665015897e+60, 7.254547591145725e-49)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fac_byn_density_probs[0,0], fou_byn_density_probs[0,0], kar_byn_density_probs[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob. à priori por view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiago/.anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "fac_byn_y_pred, fac_byn_posteriori_probs = calc_prob_posteriori(fac_byn_density_probs, Pw)\n",
    "fou_byn_y_pred, fou_byn_posteriori_probs = calc_prob_posteriori(fou_byn_density_probs, Pw)\n",
    "kar_byn_y_pred, kar_byn_posteriori_probs = calc_prob_posteriori(kar_byn_density_probs, Pw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regra da soma\n",
    "\n",
    "Precisei tirar o fac porque seus valores são nulos. TENTAR CORRIGIR ISSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regra_soma_padrao(views, Pw):\n",
    "    qtd_x = views[0].shape[0]\n",
    "    qtd_w = len(Pw)\n",
    "    x_sum_w = np.empty((qtd_x, qtd_w))\n",
    "\n",
    "    for i in range(qtd_x):\n",
    "        for k in range(qtd_w):\n",
    "            views_sum = sum([v[i,k] for v in views])\n",
    "            x_sum_w[i,k] = (1-len(views))*Pw[k] + views_sum\n",
    "                    \n",
    "    y_pred = x_sum_w.argmax(axis = 1) \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimador do scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "class ClassificaforBayesiano(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, partition, Pw):\n",
    "        self.partition = partition\n",
    "        self.Pw = Pw\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "         \n",
    "        self.classes_ = unique_labels(y)\n",
    "        self._fit_gaussian_bayesian_data(X)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        return self\n",
    "    \n",
    "    def _fit_gaussian_bayesian_data(self, X):\n",
    "        n, d = X.shape\n",
    "        qtd_w = len(self.partition)\n",
    "        self.means = np.array([X[idxs].mean(axis=0) for idxs in self.partition])\n",
    "        self.var = np.array([((X[idxs]-self.means[i])**2).mean(axis=0) for i, idxs in enumerate(self.partition)])\n",
    "        self.cov_matrix = [np.zeros((d,d)) for _ in range(qtd_w)]\n",
    "\n",
    "        for i in range(qtd_w):\n",
    "            np.fill_diagonal(self.cov_matrix[i], self.var[i])\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _calc_gaussian_density_prob(self, xk, cls):\n",
    "        d = xk.shape[0]\n",
    "        coef = np.power(2*np.pi, -d/2)\n",
    "        inv_cov_matrix = np.linalg.inv(self.cov_matrix[cls])\n",
    "        (sign, logdet) = np.linalg.slogdet(inv_cov_matrix)\n",
    "        sqrt_det_inv_cov = np.sqrt(sign*np.exp(logdet))\n",
    "        diff = xk - self.means[cls]\n",
    "        exp_exp = np.dot((-1/2)*np.dot(diff.T, inv_cov_matrix), diff)\n",
    "        exp_func = np.exp(exp_exp)\n",
    "\n",
    "        return coef * sqrt_det_inv_cov * exp_func\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        \n",
    "        desity_probs = np.empty((X.shape[0], len(self.classes_)))\n",
    "        for k in range(desity_probs.shape[0]):\n",
    "            for j in range(len(self.classes_)):\n",
    "                desity_probs[k,j] = self._calc_gaussian_density_prob(X[k], j)\n",
    "        \n",
    "        post_probs = calc_prob_posteriori(desity_probs, self.Pw)\n",
    "        \n",
    "        return post_probs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegraSomaClasificadorBayesiano(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, partition, Pw):\n",
    "#         self.views = views\n",
    "        self.partition = partition\n",
    "        self.Pw = Pw\n",
    "        self.clfs = []        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "#         X, y = check_X_y(X, y)\n",
    "         \n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        for x in X:\n",
    "            clf = ClassificaforBayesiano(self.partition, Pw)\n",
    "            clf.fit(x,y)\n",
    "            self.clfs.append(clf)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        assert len(X) == len(self.clfs)\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "#         X = check_array(X)\n",
    "        \n",
    "        post_probs = [clf.predict_proba(x) for clf, x in zip(self.clfs, X)]\n",
    "        \n",
    "        return self.regra_soma(post_probs, Pw=self.Pw)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"Pw\": self.Pw, \"partition\": self.partition}\n",
    "    \n",
    "    def regra_soma(self, matrizes, Pw):\n",
    "        qtd_x = matrizes[0].shape[0]\n",
    "        qtd_w = len(Pw)\n",
    "        x_sum_w = np.empty((qtd_x, qtd_w))\n",
    "        \n",
    "        for i in range(qtd_x):\n",
    "            for k in range(qtd_w):\n",
    "                views_sum = sum([v[i,k] for v in matrizes])\n",
    "                # views_sum =  fac_p_w_x[i,k] fou_p_w_x[i,k] + kar_p_w_x[i,k]\n",
    "                x_sum_w[i,k] = (1-len(matrizes))*Pw[k] + views_sum\n",
    "                \n",
    "        y_pred = x_sum_w.argmax(axis = 1) \n",
    "        return y_pred\n",
    "\n",
    "# def regra_soma_padrao(fac_p_w_x, fou_p_w_x, kar_p_w_x, Pw):\n",
    "# x_sum_w = np.empty((10, 2000))\n",
    "\n",
    "# for i in range(10):\n",
    "#     for k in range(2000):\n",
    "#         views_sum =  fou_p_w_x[i,k] + kar_p_w_x[i,k]\n",
    "#         # views_sum =  fac_p_w_x[i,k] fou_p_w_x[i,k] + kar_p_w_x[i,k]\n",
    "#         x_sum_w[i,k] = (1-2)*Pw[i] + views_sum\n",
    "\n",
    "# y_pred = x_sum_w.argmax(axis = 0) \n",
    "# return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100 2/100 3/100 4/100 5/100 6/100 7/100 8/100 9/100 10/100 11/100 12/100 13/100 14/100 15/100 16/100 17/100 18/100 19/100 20/100 21/100 22/100 23/100 24/100 25/100 26/100 27/100 28/100 29/100 30/100 31/100 32/100 33/100 34/100 35/100 36/100 37/100 38/100 39/100 40/100 41/100 42/100 43/100 44/100 45/100 46/100 47/100 48/100 49/100 50/100 \n",
      "\n",
      "Acurácia parcial: 0.7238 +/- (0.027010368379568616)\n",
      "Medida-F parcial: 0.6575911422781199 +/- (0.031279227732342436)\n",
      "\n",
      "51/100 52/100 53/100 54/100 55/100 56/100 57/100 58/100 59/100 60/100 61/100 62/100 63/100 64/100 65/100 66/100 67/100 68/100 69/100 70/100 71/100 72/100 73/100 74/100 75/100 76/100 77/100 78/100 79/100 80/100 81/100 82/100 83/100 84/100 85/100 86/100 87/100 88/100 89/100 90/100 91/100 92/100 93/100 94/100 95/100 96/100 97/100 98/100 99/100 100/100 \n",
      "\n",
      "Acurácia parcial: 0.7235 +/- (0.026091186251299504)\n",
      "Medida-F parcial: 0.6583459406076162 +/- (0.030174762922527264)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "FOLDS = 10\n",
    "REPEATS = 10\n",
    "\n",
    "def get_splited_partition(idxs, y_true):\n",
    "    partition = [[] for i in range(10)]\n",
    "    \n",
    "    for i,indice in enumerate(idxs):\n",
    "        partition[y_true[indice]].append(i)\n",
    "        \n",
    "    return partition\n",
    "    \n",
    "cv = RepeatedStratifiedKFold(FOLDS, REPEATS, RANDOM_SEED)\n",
    "acc_scores = np.empty((cv.get_n_splits(),))\n",
    "f1_scores = np.empty((cv.get_n_splits(),))\n",
    "\n",
    "#views = [fac, fou, kar]\n",
    "views = [fou, kar]\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(cv.split(fac, y_true)):\n",
    "    print(f\"{i+1}/{cv.get_n_splits()}\", end=\" \")\n",
    "    \n",
    "    test_views = [v[test_index] for v in views]\n",
    "    train_views = [v[train_index] for v in views]\n",
    "    \n",
    "    local_partition = get_splited_partition(train_index, y_true)\n",
    "    clf = RegraSomaClasificadorBayesiano(local_partition, Pw)\n",
    "    \n",
    "    clf.fit(train_views, y_true[train_index])\n",
    "    \n",
    "    y_pred = clf.predict(test_views)\n",
    "    \n",
    "    acc_scores[i] = accuracy_score(y_true[test_index], y_pred)\n",
    "    f1_scores[i] = f1_score(y_true[test_index], y_pred, average=\"macro\") \n",
    "    \n",
    "    if (i+1)%50 == 0:\n",
    "        print\n",
    "        print(f\"\\n\\nAcurácia parcial: {acc_scores[:i+1].mean()} +/- ({acc_scores[:i+1].std()})\")\n",
    "        print(f\"Medida-F parcial: {f1_scores[:i+1].mean()} +/- ({f1_scores[:i+1].std()})\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Vizinhos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "fac_norm = minmax_scale(fac)\n",
    "fou_norm = minmax_scale(fou)\n",
    "kar_norm = minmax_scale(kar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distâncias entre os elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "fac_dist = euclidean_distances(fac_norm, fac_norm)\n",
    "fou_dist = euclidean_distances(fou_norm, fou_norm)\n",
    "kar_dist = euclidean_distances(kar_norm, kar_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de densidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_knn_density_prob(view_dists, k, Pw, y_true):\n",
    "    qtd_x = view_dists.shape[0]\n",
    "    qtd_w = len(Pw)\n",
    "    \n",
    "    p_x_w = np.empty((qtd_x, qtd_w))\n",
    "    k_vizinhos = view_dists.argsort(axis=1)[:,:k+1]\n",
    "    \n",
    "    for j in range(qtd_x):\n",
    "        w_vizinhos = y_true[k_vizinhos[j, 1:]]\n",
    "        for i in range(qtd_w):\n",
    "            p_x_w[j,i] = (w_vizinhos == i).sum()/k\n",
    "                    \n",
    "    return p_x_w\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desidades por dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac_knn_density_probs = calc_knn_density_prob(fac_dist, 5, Pw, y_true)\n",
    "fou_knn_density_probs = calc_knn_density_prob(fou_dist, 5, Pw, y_true)\n",
    "kar_knn_density_probs = calc_knn_density_prob(kar_dist, 5, Pw, y_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob. à posteriori por view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, fac_knn_posteriori_probs = calc_prob_posteriori(fac_knn_density_probs, Pw)\n",
    "_, fou_knn_posteriori_probs = calc_prob_posteriori(fou_knn_density_probs, Pw)\n",
    "_, kar_knn_posteriori_probs = calc_prob_posteriori(kar_knn_density_probs, Pw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regra da soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia:  0.8125\n",
      "Medida-F:  0.6759567552071272\n"
     ]
    }
   ],
   "source": [
    "y_pred_knn_all = regra_soma_padrao([fac_knn_posteriori_probs, \n",
    "                                   fou_knn_posteriori_probs, \n",
    "                                   kar_knn_posteriori_probs], Pw)\n",
    "\n",
    "print(\"Acurácia: \", accuracy_score(y_true, y_pred_knn_all))\n",
    "print(\"Medida-F: \", f1_score(y_true, y_pred_knn_all, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100 2/100 3/100 4/100 5/100 6/100 7/100 8/100 9/100 10/100 11/100 12/100 13/100 14/100 15/100 16/100 17/100 18/100 19/100 20/100 \n",
      "\n",
      "Acurácia parcial: 0.8083888888888889 +/- (0.003804237403504441)\n",
      "Medida-F parcial: 0.6707240742627215 +/- (0.007462663578810034)\n",
      "\n",
      "21/100 22/100 23/100 24/100 25/100 26/100 27/100 28/100 29/100 30/100 31/100 32/100 33/100 34/100 35/100 36/100 37/100 38/100 39/100 40/100 \n",
      "\n",
      "Acurácia parcial: 0.8081805555555555 +/- (0.003922449434715664)\n",
      "Medida-F parcial: 0.6705258842364112 +/- (0.006495137081714233)\n",
      "\n",
      "41/100 42/100 43/100 44/100 45/100 46/100 47/100 48/100 49/100 50/100 51/100 52/100 53/100 54/100 55/100 56/100 57/100 58/100 59/100 60/100 \n",
      "\n",
      "Acurácia parcial: 0.8084166666666667 +/- (0.004131113750920595)\n",
      "Medida-F parcial: 0.6707166403459527 +/- (0.006392253215130073)\n",
      "\n",
      "61/100 62/100 63/100 64/100 65/100 66/100 67/100 68/100 69/100 70/100 71/100 72/100 73/100 74/100 75/100 76/100 77/100 78/100 79/100 80/100 \n",
      "\n",
      "Acurácia parcial: 0.8083750000000001 +/- (0.004489163048558515)\n",
      "Medida-F parcial: 0.6705123902707658 +/- (0.00673732479742659)\n",
      "\n",
      "81/100 82/100 83/100 84/100 85/100 86/100 87/100 88/100 89/100 90/100 91/100 92/100 93/100 94/100 95/100 96/100 97/100 98/100 "
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(FOLDS, 10, RANDOM_SEED)\n",
    "train_acc_scores = np.empty((cv.get_n_splits(),))\n",
    "train_f1_scores = np.empty((cv.get_n_splits(),))\n",
    "\n",
    "views = [fac_norm, fou_norm, kar_norm]\n",
    "k = 5\n",
    "for i, (train_index, test_index) in enumerate(cv.split(fac, y_true)):\n",
    "    print(f\"{i+1}/{cv.get_n_splits()}\", end=\" \")\n",
    "    \n",
    "    test_views = [v[test_index] for v in views]\n",
    "    train_views = [v[train_index] for v in views]\n",
    "    train_views_dists = [euclidean_distances(v,v) for v in train_views]\n",
    "    test_views_dists = [euclidean_distances(v,v) for v in test_views]\n",
    "    \n",
    "#     y_true_split = get_splited_partition(train_index, y_true)\n",
    "    \n",
    "    train_views_density_probs = [calc_knn_density_prob(v, k, Pw, y_true[train_index]) \n",
    "                                 for v in train_views_dists]\n",
    "    \n",
    "    train_views_post_probs = [calc_prob_posteriori(v, Pw) \n",
    "                              for v in train_views_density_probs]\n",
    "    \n",
    "    y_pred_train = regra_soma_padrao(train_views_post_probs, Pw)\n",
    "    \n",
    "    train_acc_scores[i] = accuracy_score(y_true[train_index], y_pred_train)\n",
    "    train_f1_scores[i] = f1_score(y_true[train_index], y_pred_train, average=\"macro\") \n",
    "    \n",
    "    if (i+1)%20 == 0:\n",
    "        print(f\"\\n\\nAcurácia parcial: {train_acc_scores[:i+1].mean()} +/- ({train_acc_scores[:i+1].std()})\")\n",
    "        print(f\"Medida-F parcial: {train_f1_scores[:i+1].mean()} +/- ({train_f1_scores[:i+1].std()})\\n\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Janela de Parzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de densidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parzen_density_function(view, h, partition):\n",
    "#     p_x_w = np.empty((10, 2000))\n",
    "#     dims = view.shape[1]\n",
    "#     elements_in_window = np.empty((10, dims))\n",
    "    \n",
    "#     def K(x):\n",
    "#         return np.exp(-x**2/2)/np.sqrt(2*np.pi)\n",
    "\n",
    "#     for i in range(10):\n",
    "#         n = len(partition[i])\n",
    "#         for k in range(2000):\n",
    "#             p = np.array([np.array([K((view[k,j] - view[e,j])/h) for j in range(dims)]).prod() \n",
    "#                  for e in partition[i]]).sum()\n",
    "            \n",
    "#             p_x_w[i,k] = (1/(n*h**dims))\n",
    "            \n",
    "#     return p_x_w\n",
    "\n",
    "def parzen_density_function(view, h, partition):\n",
    "    p_x_w = np.empty((2000, 10))\n",
    "    dims = view.shape[1]\n",
    "    \n",
    "    for i in range(10):\n",
    "        n = len(partition[i])\n",
    "        x_view = view[partition[i],:]\n",
    "        \n",
    "        for k in range(2000):\n",
    "            diff = (view[k] - x_view)/h\n",
    "            gaussian_diff = np.exp(-diff**2/2)/np.sqrt(2*np.pi)\n",
    "            prod_dims = gaussian_diff.prod(axis=0)\n",
    "            p_x_w[k,i] = (1/(n*h**dims)) * prod_dims.sum()\n",
    "            print(p_x_w[k,i])\n",
    "            \n",
    "    return p_x_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac_parzen_density_probs = parzen_density_function(fac, 50, partition)\n",
    "fou_parzen_density_probs = parzen_density_function(fou, 50, partition)\n",
    "kar_parzen_density_probs = parzen_density_function(kar, 50, partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidade a priori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac_prazen_y_pred, fac_prazen_posteriori_probs = calc_prob_posteriori(fac_parzen_density_probs, Pw)\n",
    "fou_prazen_y_pred, fou_prazen_posteriori_probs = calc_prob_posteriori(fou_parzen_density_probs, Pw)\n",
    "fou_prazen_y_pred, kar_prazen_posteriori_probs = calc_prob_posteriori(kar_parzen_density_probs, Pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prazen_pred_all = regra_soma_padrao(fac_prazen_posteriori_probs, \n",
    "                                    fou_prazen_posteriori_probs, \n",
    "                                    kar_prazen_posteriori_probs, Pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_prazen_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "y_true = clustering.get_instances_class()\n",
    "\n",
    "print(\"Acurácia: \", accuracy_score(y_true, y_prazen_pred_all))\n",
    "print(\"Medida-F: \", f1_score(y_true, y_prazen_pred_all, average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "262px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
